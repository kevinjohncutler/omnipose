{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5ead9f-ade1-45dc-9e47-5ea0ea2743f9",
   "metadata": {},
   "source": [
    "# Figure 6 and Extended Data Figure 8\n",
    "Here we want to pull out a good example from the cyto2 dataset. Cellpose and Omnipose really 'trade blows', so to speak - there are plenty of cases where one fails where the other succeeds. Generally this happens in cases where cells overlap or are otherwise ambiguous. Our performance metrics show more or less equivalent performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5697b9c-0660-4376-b390-80da97eb52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# First, import dependencies.\n",
    "import numpy as np\n",
    "import time, os, sys\n",
    "from cellpose_omni import models, core, utils, io\n",
    "import skimage.io\n",
    "import omnipose\n",
    "\n",
    "# This checks to see if you have set up your GPU properly.\n",
    "# CPU performance is a lot slower, but not a problem if you are only processing a few images.\n",
    "use_GPU = core.use_gpu()\n",
    "print('>>> GPU activated? %d'%use_GPU)\n",
    "\n",
    "# for plotting \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a406d-e58e-4fc3-b7df-5f0813147a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = ['/home/kcutler/DataDrive/cyto2/test/005_img.tif']\n",
    "basedir = '/home/kcutler/DataDrive/cyto2/test/'\n",
    "mask_filter = '_masks'\n",
    "img_filter = '_img'\n",
    "img_names = io.get_image_files(basedir, mask_filter, img_filter)\n",
    "mask_names = io.get_label_files(img_names, mask_filter, img_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764ab36-fe7b-4bbc-844f-34d33bcf3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_only = 0\n",
    "if multi_only:\n",
    "    files = []\n",
    "    maskfiles = []\n",
    "    for path,maskpath in zip(img_names,mask_names):\n",
    "        im = skimage.io.imread(path)\n",
    "        if np.any(im[0]) and np.any(im[1]):\n",
    "            files.append(path)\n",
    "            maskfiles.append(maskpath)\n",
    "            print(im.shape)\n",
    "else:\n",
    "    files = img_names\n",
    "    maskfiles = mask_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e20b44-d020-480a-ae33-fa560a41968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getname(path,suffix='_masks'):\n",
    "#     return os.path.splitext(Path(path).name)[0].replace(suffix,'')\n",
    "# names = [getname(path) for path in mask_names]\n",
    "# select = [5,27]\n",
    "# files = [path for path,name in zip(img_names,names) if any('%03d' % (n,)  in name for n in select)]\n",
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b84650-a845-4aa5-9e3e-d817c4b2a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [skimage.io.imread(f) for f in files]\n",
    "masks_gt = [skimage.io.imread(f) for f in maskfiles]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b2825-87c5-4dbd-b86e-3166b4dcebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diameters = [omnipose.core.diameters(mask) for mask in masks_gt]\n",
    "np.mean(diameters),len(diameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebadf8cd-e391-433d-a8c7-d54b3c810e7a",
   "metadata": {},
   "source": [
    "The images in cyto2 generally have cytoplasm in channel 1 (red) and nuclei in channel 2 (green), not related to how the actual data was acquired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd5f1b-43b8-4b83-9b76-35dc79be1735",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cellpose_omni import io, transforms, plot\n",
    "\n",
    "# for i in imgs:\n",
    "#     print(i.shape)\n",
    "nimg = len(imgs)\n",
    "print(nimg)\n",
    "\n",
    "plt.figure(figsize=[20]*2) # initialize figure\n",
    "for k in range(len(imgs)):\n",
    "    img = transforms.move_min_dim(imgs[k]) # move the channel dimension last\n",
    "    imgs[k] = transforms.normalize99(img,omni=True)\n",
    "    print(imgs[k].shape,k)\n",
    "    # plt.subplot(1,len(files),k+1)\n",
    "    # rgb = np.stack((imgs[k][0],imgs[k][1],np.zeros_like(imgs[k][0])),axis=-1)\n",
    "    # plt.imshow(plot.image_to_rgb(imgs[k])) \n",
    "    # plt.axis('off')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd1c00-c3dd-4e6a-8fa2-daf9cd814eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = ['cyto2','cyto2_omni']\n",
    "# L = len(model_name)\n",
    "# model = [models.CellposeModel(gpu=use_GPU, model_type=model_name[i]) for i in range(L)]\n",
    "model_name = ['cyto2','cyto2_omni_bit loss']\n",
    "L = len(model_name)\n",
    "\n",
    "modeldir = '/home/kcutler/DataDrive/cyto2/train/models/cellpose_residual_on_style_on_concatenation_off_omni_train_2022_04_15_00_39_49.881936_epoch_301' #oops, no size model! maybe that's why it is taking cyto2 so long to train \n",
    "modeldir = '/home/kcutler/DataDrive/cyto2/train/models/cellpose_residual_on_style_on_concatenation_off_omni_train_2022_04_16_01_24_45.606751_epoch_2501'\n",
    "# the next model I am trainignis with my big cell fixes and rescaling to 35 instead of 30, closer to the mean diameter of the dataset\n",
    "# will need to validate the szmean is loaded!! \n",
    "modeldir = '/home/kcutler/DataDrive/cyto2/train/models/cellpose_residual_on_style_on_concatenation_off_omni_train_2022_04_22_17_55_58.018802_epoch_2601'\n",
    "\n",
    "# model = [models.CellposeModel(gpu=use_GPU, model_type='cyto2'), models.CellposeModel(gpu=use_GPU, pretrained_model=modeldir)]\n",
    "# model = [models.CellposeModel(gpu=use_GPU, pretrained_model=modeldir)] \n",
    "model = [models.CellposeModel(gpu=use_GPU, model_type='cyto2'),\n",
    "         models.CellposeModel(gpu=use_GPU, model_type='cyto2_omni',diam_mean=36)] #SO it appears like new model 701 is already better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad54a0f-5a24-43c7-9ea1-ad5d6401faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chans = [[2,3],[2,1]] # green cytoplasm and blue nucleus; cellpose documentation is confusing about this\n",
    "chans = [[1,2],[2,1]] # cyto2 makes more sense \n",
    "# chans = [[1,2],[1,2]]\n",
    "# chans = [[1,1]]\n",
    "\n",
    "n = range(nimg) \n",
    "# n = [-2]\n",
    "# n = [-4]\n",
    "# n = range(10,15)\n",
    "n = [-1]\n",
    "# [-5] is bad\n",
    "n = [1]\n",
    "# define parameters\n",
    "mask_threshold = [0,0,-1]\n",
    "verbose = 0 # turn on if you want to see more output \n",
    "use_gpu = use_GPU #defined above\n",
    "transparency = True # transparency in flow output\n",
    "rescale= None # give this a number if you need to upscale or downscale your images\n",
    "flow_threshold = 0 # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "resample = True #whether or not to run dynamics on rescaled grid or original grid \n",
    "\n",
    "N = L+1 # three options: pure cellpose, mixed, omnipose, new omnipose\n",
    "omni = [0,1,1]\n",
    "ind = [0,0,1]\n",
    "masks, flows, styles = [[]]*N, [[]]*N, [[]]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0051f3a8-6965-4bdb-b785-5d385ec86962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t = [[]]*N\n",
    "# for i in range(N):\n",
    "# for i in [0,-1]:\n",
    "# n = [-5]\n",
    "chans=[[1,2],[2,1]]\n",
    "# n = range(nimg) \n",
    "# n = [49]\n",
    "flow_threshold = 0\n",
    "for i in [-1]:\n",
    "    start_time = time.time()\n",
    "    masks[i], flows[i], styles[i] = model[ind[i]].eval([imgs[k] for k in n],channels=chans[ind[i]],diameter=[diameters[k] for k in n],mask_threshold=mask_threshold[i],\n",
    "                                               transparency=transparency,flow_threshold=flow_threshold,omni=omni[i], #toggle omni \n",
    "                                               resample=resample, verbose=verbose, cluster=omni[i],interp=True) #omni[i]\n",
    "    t[i] = time.time() - start_time\n",
    "    print(t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46bae76-d451-491e-a256-f20fcc0e5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(plot.image_to_rgb(imgs[2]))\n",
    "diameters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6c0b2-0585-48c1-8857-c1dfaa21db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs[n[0]-1].shape\n",
    "# plt.imshow(omnipose.utils.normalize99(imgs[-5][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feeca03-68df-4273-9457-74fe2a9a43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "from cellpose_omni import plot\n",
    "import omnipose\n",
    "\n",
    "for idx,i in enumerate(n):\n",
    "    \n",
    "    # for k,ki in enumerate(ind):\n",
    "    for k in [-1]:\n",
    "        ki = ind[k]\n",
    "        print('model is:',model_name[ki],', omni is:',omni[ki])\n",
    "        maski = masks[k][idx]\n",
    "        flowi = flows[k][idx][0]\n",
    "        print('m',maski.shape,imgs[i].shape,'chans',chans[i%2])\n",
    "        fig = plt.figure(figsize=(12,5))\n",
    "        # im = transforms.move_min_dim(imgs[i])\n",
    "        # print(im.shape)\n",
    "        # plot.show_segmentation(fig, omnipose.utils.normalize_image(imgs[i],1-masks_gt[i]>0,bg = .4), maski, flowi, channels=chans[i%2], omni=True, bg_color=0)\n",
    "        if not np.any(imgs[i][1]):\n",
    "            im = imgs[i][0]\n",
    "        else:\n",
    "            im = imgs[i]\n",
    "        plot.show_segmentation(fig, im, maski, flowi, channels=chans[i%2], omni=1, bg_color=0)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc528e-51c1-4cee-8451-9cd3146817e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.cm.get_cmap('plasma')\n",
    "outline_col = cmap(0.85)[:3]\n",
    "k = -1\n",
    "io.save_masks([imgs[i] for i in n], [masks[k][i] for i in n], [flows[k][i] for i in n], [files[i] for i in n], \n",
    "              tif=True, #whether to use PNG or TIF format\n",
    "              suffix='', # suffix to add to files if needed \n",
    "              save_flows=True, \n",
    "              save_outlines=True, # save outline images \n",
    "              outline_col = outline_col,\n",
    "              dir_above=0, # save output in the image directory or in the directory above (at the level of the image directory)\n",
    "              in_folders=True, # save output in folders (recommended)\n",
    "              save_txt=False, # txt file for outlines in imageJ\n",
    "              save_ncolor=True) # save ncolor version of masks for visuaizatin and editing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d6f1d-ff19-4f29-a570-cbc6216ff6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [49]\n",
    "n = range(nimg) \n",
    "imlist = []\n",
    "chanlist = []\n",
    "for i in n:\n",
    "    if not np.any(imgs[i][1]):\n",
    "        imlist.append(imgs[i][0])\n",
    "        # chanlist.append([0,0])\n",
    "    else:\n",
    "        imlist.append(imgs[i])\n",
    "        # chanlist.append([2,1])\n",
    "io.save_masks(imlist, [masks[k][i] for i in n], [flows[k][i] for i in n], [files[i] for i in n], \n",
    "              tif=True, #whether to use PNG or TIF format\n",
    "              suffix='', # suffix to add to files if needed \n",
    "              save_flows=0, \n",
    "              save_outlines=True, # save outline images \n",
    "              outline_col = outline_col,\n",
    "              dir_above=0, # save output in the image directory or in the directory above (at the level of the image directory)\n",
    "              in_folders=True, # save output in folders (recommended)\n",
    "              save_txt=False, # txt file for outlines in imageJ\n",
    "              save_ncolor=0, # save ncolor version of masks for visuaizatin and editing \n",
    "              omni=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923fb788-23a5-4c2a-a239-47e561aba5ed",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save0 = os.path.join('/home/kcutler/DataDrive/omnipose_paper/Figure S8/cyto2/crop_outlines')\n",
    "io.check_dir(save0)\n",
    "ext='.png'\n",
    "n = range(nimg) \n",
    "# n = [49]\n",
    "imlist = []\n",
    "chanlist = []\n",
    "k = -1\n",
    "for i in n:\n",
    "    \n",
    "    if not np.any(imgs[i][1]):\n",
    "        img0 = imgs[i][0]\n",
    "    else:\n",
    "        img0 = imgs[i]\n",
    "    \n",
    "    mgt = masks[k][i]\n",
    "    s = mgt.shape\n",
    "    L = np.min(s)\n",
    "    outli = plot.outline_view(img0,mgt,color=outline_col)#,mode='thick')\n",
    "    \n",
    "    slc = (slice(0,L),)*2\n",
    "    crop_outli = outli[slc]\n",
    "    \n",
    "    # plt.imshow(crop_outli,interpolation='none')\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    \n",
    "    name = '%03d' % (i,) \n",
    "\n",
    "    # save the outlines\n",
    "    savepath = os.path.join(save0,name+'_crop_outlines'+ext)\n",
    "    io.imsave(savepath,crop_outli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7720b6-9081-4041-9372-bbbf1e987186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crop_outli.shape,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590cf7f-7f5b-447f-b8b0-fc4694ea2d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e70e9-d5e8-4dcd-b143-116fcffca661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "mu = flows[k][idx][1]\n",
    "f = scipy.ndimage.zoom(mu, tuple([1,2,2]), order=1)\n",
    "f.shape, mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2990084-6586-4e00-8472-1ad1a8b8cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit \n",
    "a = 2.1\n",
    "b = 1.9\n",
    "# f = scipy.ndimage.zoom(mu, tuple([1,a,b]), order=1)\n",
    "scipy.ndimage.zoom(imgs[0], a, order=1).shape,imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d3364-318d-4800-8871-89f5f73e869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "a = 2.1\n",
    "b = 1.9\n",
    "# f = scipy.ndimage.zoom(mu, tuple([1,a,b]), order=1)\n",
    "np.stack([ scipy.ndimage.zoom(mu[k], tuple([a,b]), order=1) for k in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52656293-f2e4-4a7e-a838-8dad4b633d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = flows[k][idx][4]\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "plt.imshow(sigmoid(bd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1bf50c-e142-441c-b65f-54570dafe8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = flows[k][idx][1]\n",
    "div = omnipose.core.divergence(mu)\n",
    "plt.imshow(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e21cac-7807-4c6a-9a7b-e1c6dede4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "plt.imshow(masks_gt[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da84a3b-0ef2-48fd-8bc9-226d9d7a06e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ncolor\n",
    "save0 = os.path.join('/home/kcutler/DataDrive/omnipose_paper/Figure 6/cyto2')\n",
    "io.check_dir(save0)\n",
    "\n",
    "# define outline color\n",
    "cmap = mpl.cm.get_cmap('plasma')\n",
    "outline_col = cmap(0.85)[:3]\n",
    "ext = '.png'\n",
    "\n",
    "k = -1 # k denotes the model \n",
    "pad = 10\n",
    "labels = [34,36]\n",
    "name = ['cellpose','mixed','omnipose']\n",
    "for idx,i in enumerate(n):\n",
    "    print('model is:',name[j],', omni is:',omni[j])\n",
    "    mgt = masks_gt[i]\n",
    "    bin0 = np.zeros_like(mgt)\n",
    "    for l in labels:\n",
    "        bin0[mgt==l] = 1\n",
    "    \n",
    "    inds = np.nonzero(bin0)\n",
    "    max_inds = np.array(bin0.shape)-1\n",
    "    slc = tuple([slice(max(0,min(inds[k])-pad),min(max_inds[k],max(inds[k])+pad)) for k in range(mgt.ndim)])\n",
    "    \n",
    "    crop_img = imgs[i][(Ellipsis,)*(imgs[i].ndim-2)+slc]\n",
    "    crop_masks = masks[k][idx][slc]\n",
    "    crop_flow = flows[k][idx][0][slc]\n",
    "    \n",
    "    crop_outli = plot.outline_view(crop_img,crop_masks,color=outline_col)#,mode='thick')\n",
    "\n",
    "    plt.imshow(crop_outli,interpolation='none')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    basedir = os.path.join(save0,name[j])\n",
    "    io.check_dir(basedir)\n",
    "    # save the cropped image, RGB uint8 is not interpolated in illustrator ;) \n",
    "    img0 = np.stack([crop_img,]*3,axis=-1)\n",
    "    savepath = os.path.join(basedir,'crop_img'+ext)\n",
    "    io.imsave(savepath,np.uint8(img0*(2**8-1)))\n",
    "\n",
    "    # save the outlines\n",
    "    savepath = os.path.join(basedir,'crop_outlines'+ext)\n",
    "    io.imsave(savepath,crop_outli)\n",
    "\n",
    "    # save the masks\n",
    "    savepath = os.path.join(basedir,'crop_masks'+ext)\n",
    "    io.imsave(savepath,np.uint8(crop_masks))\n",
    "\n",
    "    # save the flows\n",
    "    savepath = os.path.join(basedir,'crop_flows'+ext)\n",
    "    skimage.io.imsave(savepath,np.uint8(crop_flow))\n",
    "\n",
    "    # save the distance\n",
    "    savepath = os.path.join(basedir,'crop_dist'+ext)\n",
    "    dist = omnipose.utils.rescale(flows[k][idx][2][slc])\n",
    "    cmap = mpl.cm.get_cmap('plasma')\n",
    "    pic = cmap(dist)\n",
    "    pic[:,:,-1] = crop_masks>0\n",
    "    skimage.io.imsave(savepath,np.uint8(pic*(2**8-1)))\n",
    "\n",
    "    # save the boundary\n",
    "    savepath = os.path.join(basedir,'crop_bd'+ext)\n",
    "    dist = omnipose.utils.rescale(flows[k][idx][4][slc])\n",
    "    cmap = mpl.cm.get_cmap('viridis')\n",
    "    pic = cmap(dist)\n",
    "    pic[:,:,-1] = crop_masks>0\n",
    "    skimage.io.imsave(savepath,np.uint8(pic*(2**8-1)))\n",
    "\n",
    "    #save a grayscale version for adobe illustator vectorization \n",
    "    ncl = ncolor.label(crop_masks)\n",
    "    grey_n = np.stack([1-omnipose.utils.rescale(ncl)]*3,axis=-1)\n",
    "    savepath = os.path.join(basedir,'masks_gray'+ext)\n",
    "    io.imsave(savepath,np.uint8(grey_n*(2**8-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda10b12-32f6-4f0b-a8a1-6ad7a0bc60fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional examples from cyto2\n",
    "img_idx = [34,49,51,67,66,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d02e56-5ad0-47ac-9f53-ab4f9e3c3411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = ['/home/kcutler/DataDrive/cyto2/test/005_img.tif']\n",
    "basedir = '/home/kcutler/DataDrive/cyto2/test/'\n",
    "mask_filter = '_masks'\n",
    "imf = '_img'\n",
    "img_names = io.get_image_files(basedir, mask_filter, imf)\n",
    "mask_names,flow_names = io.get_label_files(img_names, mask_filter, imf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f939a7c-66b9-44f7-a39e-4fb0be6be973",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = skimage.io.imread('/home/kcutler/DataDrive/cyto2/test/005_img.tif')\n",
    "mask = skimage.io.imread('/home/kcutler/DataDrive/cyto2/test/005_masks.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a8736-def2-4168-9f28-216dea768b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "fig = plt.figure(figsize=(20,)*2)\n",
    "plt.imshow(plot.outline_view(omnipose.utils.normalize99(im), mask))\n",
    "\n",
    "# plt.imshow(plot.image_to_rgb(im,omni=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d146d5-ca76-44ee-b016-1e291c6f8c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "import ncolor\n",
    "from omnipose.utils import sinebow, normalize99\n",
    "c = sinebow(5)\n",
    "colors = np.array(list(c.values()))[1:]\n",
    "im = normalize99(transforms.move_min_dim(im))\n",
    "if im.ndim>2:\n",
    "    img0 = im.mean(axis=-1)\n",
    "else:\n",
    "    img0 = im\n",
    "overlay = color.label2rgb(ncolor.label(mask,max_depth=20),img0,colors,bg_label=0,alpha=1/3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c759b-69cc-4f68-9117-64d649cec271",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305894a2-47e9-41d2-926c-8f068e81ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape,transforms.reshape(im,channels=[1,2]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0ca1b-e62d-4680-aea4-be49fe75d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "im0 = imgs[i]\n",
    "im = omnipose.utils.normalize_image(im0,1-masks_gt[i]>0,bg = .6)\n",
    "plt.imshow(np.hstack((np.stack((im0[0],im0[1],np.zeros_like(im0[0])),axis=-1),np.stack((im[0],im[1],np.zeros_like(im[0])),axis=-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecef637-ceb6-4ad9-a3af-b715e3a888a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
