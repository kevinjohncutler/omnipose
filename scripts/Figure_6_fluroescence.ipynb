{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Figure 6b-d: fluorescence vs phase\n",
    "This notebook pulls out some examples to use with out fluorescence model. We begin with looking at some Francisella phase vs fluorescence segmentation. Then we select some fields of view from the fluorescence test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import dependencies.\n",
    "import numpy as np\n",
    "import time, os, sys\n",
    "\n",
    "# This checks to see if you have set up your GPU properly.\n",
    "# CPU performance is a lot slower, but not a problem if you are only processing a few images.\n",
    "use_GPU = core.use_gpu()\n",
    "print('>>> GPU activated? %d'%use_GPU)\n",
    "\n",
    "# for plotting \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "from cellpose_omni import io, transforms, plot, models, core\n",
    "import omnipose\n",
    "import skimage.io\n",
    "\n",
    "modeldir = '/home/kcutler/DataDrive/omnipose_all/fluor/train_sorted/models/cellpose_residual_on_style_on_concatenation_off_omni_train_sorted_2022_04_20_13_25_40.528729_epoch_3051'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = ['/home/kcutler/DataDrive/Francisella/multi/xy3tile_14/2_phase.png',\n",
    "         '/home/kcutler/DataDrive/Francisella/multi/xy3tile_14/4_green.png']\n",
    "\n",
    "imgs = [io.imread(f) for f in files]\n",
    "\n",
    "# print some infor about the images \n",
    "for i in imgs:\n",
    "    print(i.shape)\n",
    "nimg = len(imgs)\n",
    "print(nimg)\n",
    "\n",
    "plt.figure(figsize=[4]*2) # initialize figure\n",
    "for k in range(len(imgs)):\n",
    "    img = transforms.move_min_dim(imgs[k]) # move the channel dimension last\n",
    "    if len(img.shape)>2:\n",
    "        imgs[k] = img[:,:,1]\n",
    "        \n",
    "    imgs[k] = omnipose.utils.normalize99(imgs[k])\n",
    "    plt.subplot(1,len(files),k+1)\n",
    "    plt.imshow(imgs[k],cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['bact_omni','bact_fluor_omni']\n",
    "model = [models.CellposeModel(gpu=use_GPU, model_type=model_name[0]),\n",
    "         models.CellposeModel(gpu=use_GPU, pretrained_model=modeldir, net_avg=False, diam_mean=0, nclasses=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chans = [0,0] \n",
    "nimg = len(imgs)\n",
    "n = range(nimg) \n",
    "\n",
    "# define parameters\n",
    "mask_threshold = -1 \n",
    "verbose = 0 # turn on if you want to see more output \n",
    "use_gpu = use_GPU #defined above\n",
    "transparency = True # transparency in flow output\n",
    "rescale= None # give this a number if you need to upscale or downscale your images\n",
    "flow_threshold = 0 # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "resample = True #whether or not to run dynamics on rescaled grid or original grid \n",
    "cluster = True\n",
    "omni = True\n",
    "\n",
    "N = len(model_name)\n",
    "masks, flows, styles = [[]]*N, [[]]*N, [[]]*N\n",
    "for i in range(N):\n",
    "    masks[i], flows[i], styles[i] = model[i].eval([imgs[i]],channels=chans,rescale=rescale,mask_threshold=mask_threshold,\n",
    "                                               transparency=transparency,flow_threshold=flow_threshold,omni=omni, \n",
    "                                               resample=resample,verbose=verbose, cluster=cluster,interp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "\n",
    "    maski = masks[i][0]\n",
    "    flowi = flows[i][0][0]\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    # im = transforms.move_min_dim(imgs[i])\n",
    "    # print(im.shape)\n",
    "    plot.show_segmentation(fig, imgs[i], maski, flowi, channels=chans, omni=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save0 = os.path.join('/home/kcutler/DataDrive/omnipose_paper/Figure 6/Francisella')\n",
    "io.check_dir(save0)\n",
    "clean = 1\n",
    "if clean:\n",
    "    for j in range(nimg):\n",
    "        savedir = os.path.join(save0,model_name[j])\n",
    "        io.check_dir(savedir)\n",
    "        io.save_masks([imgs[j]], masks[j], flows[j], \n",
    "                      files[j], save_flows=True, save_outlines=True, \n",
    "                      savedir=savedir, in_folders=True, save_txt=False)\n",
    "        io.imsave(os.path.join(savedir,'img.tif'),(imgs[j]*(2**16-1)).astype(np.uint16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the interative widget allows us to hover and find out the index of the cell we want to grab\n",
    "\n",
    "%matplotlib widget\n",
    "plt.imshow(masks[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make outline view\n",
    "%matplotlib inline\n",
    "import skimage.measure\n",
    "import ncolor\n",
    "ext = '.png'\n",
    "cellID = [229,235] #two cells in the same cluster from the two segmentation modes \n",
    "\n",
    "# define outline color\n",
    "cmap = mpl.cm.get_cmap('plasma')\n",
    "outline_col = cmap(0.85)[:3]\n",
    "\n",
    "# define image padding\n",
    "pad = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):  # outler loop allows once go around to grab the crop box I want, then go again to save masks etc.\n",
    "                    # by applying the second crop box to both \n",
    "    for j in range(nimg):\n",
    "        labels = masks[j][0]\n",
    "        bin0 = labels>0\n",
    "        colonies = skimage.measure.label(bin0)\n",
    "        colonyID = colonies[labels==cellID[j]]\n",
    "        colony_mask = colonies==colonyID[0]\n",
    "\n",
    "        inds = np.nonzero(colony_mask)\n",
    "        max_inds = np.array(colony_mask.shape)-1\n",
    "        \n",
    "        slc = tuple([slice(max(0,min(inds[k])-pad),min(max_inds[k],max(inds[k])+pad)) for k in range(labels.ndim)])\n",
    "\n",
    "        if j==1: # fluor\n",
    "            slc_fluor = slc\n",
    "\n",
    "        if i==1:\n",
    "            slc = slc_fluor\n",
    "\n",
    "        crop_img = imgs[j][slc]\n",
    "        crop_masks = labels[slc]\n",
    "        crop_outli = plot.outline_view(crop_img,crop_masks,color=outline_col)#,mode='thick')\n",
    "    \n",
    "        if i==1:\n",
    "            plt.imshow(crop_outli,interpolation='none')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            basedir = os.path.join(save0,model_name[j])\n",
    "            # save the cropped image, RGB uint8 is not interpolated in illustrator ;) \n",
    "            img0 = np.stack([crop_img]*3,axis=-1)\n",
    "            savepath = os.path.join(basedir,'crop_img'+ext)\n",
    "            io.imsave(savepath,np.uint8(img0*(2**8-1)))\n",
    "\n",
    "            # save the masks\n",
    "            savepath = os.path.join(basedir,'crop_masks'+ext)\n",
    "            io.imsave(savepath,np.uint8(crop_masks))\n",
    "\n",
    "            #save a grayscale version for adobe illustator vectorization \n",
    "            ncl = ncolor.label(crop_masks)\n",
    "            grey_n = np.stack([1-omnipose.utils.rescale(ncl)]*3,axis=-1)\n",
    "            savepath = os.path.join(basedir,'masks_gray'+ext)\n",
    "            io.imsave(savepath,np.uint8(grey_n*(2**8-1)))\n",
    "    \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### More fluorescence examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filter = '_masks'\n",
    "# img_names = ['/home/kcutler/DataDrive/omnipose_all/fluor/test_sorted/A22/s_flex_a22_t12xy5c1_tile1_cyto.tif',\n",
    "img_names = ['/home/kcutler/DataDrive/omnipose_all/fluor/test_sorted/cex/s_flex_cex_xy5_tile1_cyto.tif',\n",
    "             '/home/kcutler/DataDrive/omnipose_all/fluor/test_sorted/bthai/bthai_f_t010xy3_tile4_membrane.tif',\n",
    "             '/home/kcutler/DataDrive/omnipose_all/fluor/test_sorted/bthai/bthai_f_t010xy3_tile4_cyto.tif']\n",
    "mask_names,flow_names = io.get_label_files(img_names, mask_filter)\n",
    "imgs = [skimage.io.imread(f) for f in img_names]\n",
    "masks_gt = [skimage.io.imread(f) for f in mask_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bact_fluor_omni'\n",
    "model =  models.CellposeModel(gpu=use_GPU, pretrained_model=modeldir, net_avg=False, diam_mean=0, nclasses=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "chans = [0,0] \n",
    "nimg = len(imgs)\n",
    "n = range(nimg) \n",
    "\n",
    "# define parameters\n",
    "mask_threshold = -1 \n",
    "verbose = 0 # turn on if you want to see more output \n",
    "use_gpu = use_GPU #defined above\n",
    "transparency = True # transparency in flow output\n",
    "rescale= None # give this a number if you need to upscale or downscale your images\n",
    "flow_threshold = 0 # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "resample = True #whether or not to run dynamics on rescaled grid or original grid \n",
    "cluster = True\n",
    "omni = True\n",
    "\n",
    "masks, flows, styles = model.eval(imgs,channels=chans,rescale=rescale,mask_threshold=mask_threshold,\n",
    "                                               transparency=transparency,flow_threshold=flow_threshold,omni=omni, \n",
    "                                               resample=resample,verbose=verbose, cluster=cluster,interp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imgs)):\n",
    "\n",
    "    maski = masks[i]\n",
    "    flowi = flows[i][0]\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    # im = transforms.move_min_dim(imgs[i])\n",
    "    # print(im.shape)\n",
    "    plot.show_segmentation(fig, imgs[i], maski, flowi, channels=chans, omni=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ths time, use coordinates; more immune to issues re-running \n",
    "%matplotlib widget\n",
    "plt.figure(figsize=(4,)*2)\n",
    "plt.imshow(masks[0])\n",
    "plt.axis('off')\n",
    "# coords = [[76,400],[180,425]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import skimage.measure\n",
    "import ncolor\n",
    "ext = '.png'\n",
    "save0 = os.path.join('/home/kcutler/DataDrive/omnipose_paper/Figure 6/fluor_examples')\n",
    "io.check_dir(save0)\n",
    "# name = ['A22','bthai_membrane','bthai_cyto']\n",
    "name = ['cex','bthai_membrane','bthai_cyto']\n",
    "\n",
    "coords = [[400,76],[282,251],[282,251]]\n",
    "# coords = [[667,1713],[282,251],[282,251]]\n",
    "\n",
    "pad = 10\n",
    "\n",
    "cmap = mpl.cm.get_cmap('plasma')\n",
    "outline_col = cmap(0.85)[:3]\n",
    "\n",
    "nimg = len(imgs)\n",
    "for i in range(2):\n",
    "    for j in range(nimg):\n",
    "        labels = masks[j]\n",
    "        bin0 = labels>0\n",
    "        colonies = skimage.measure.label(bin0)\n",
    "        regs = skimage.measure.regionprops(colonies)\n",
    "        centroids = np.array([r.centroid for r in regs[1:]])\n",
    "        imin = np.argmin(np.sum((centroids-coords[j])**2,axis=1))\n",
    "        colony_mask = colonies==regs[imin+1].label\n",
    "\n",
    "        inds = np.nonzero(colony_mask)\n",
    "        max_inds = np.array(colony_mask.shape)-1\n",
    "\n",
    "        slc = tuple([slice(max(0,min(inds[k])-pad),min(max_inds[k],max(inds[k])+pad)) for k in range(labels.ndim)])\n",
    "\n",
    "        if j==2: # save the cyto bbox\n",
    "            slc_fluor = slc\n",
    "\n",
    "        if i==1 and j>0: # use it on membrane second time around\n",
    "            slc = slc_fluor\n",
    "\n",
    "        if i==1:\n",
    "            crop_img = omnipose.utils.normalize99(imgs[j][slc])\n",
    "            crop_masks = labels[slc]\n",
    "            crop_outli = plot.outline_view(crop_img,crop_masks,color=outline_col)#,mode='thick')\n",
    "\n",
    "\n",
    "            plt.imshow(crop_outli,interpolation='none')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            basedir = os.path.join(save0,name[j])\n",
    "            io.check_dir(basedir)\n",
    "            # save the cropped image, RGB uint8 is not interpolated in illustrator ;) \n",
    "            img0 = np.stack([crop_img,]*3,axis=-1)\n",
    "            savepath = os.path.join(basedir,'crop_img'+ext)\n",
    "            io.imsave(savepath,np.uint8(img0*(2**8-1)))\n",
    "            \n",
    "            # save the outlines\n",
    "            savepath = os.path.join(basedir,'crop_outlines'+ext)\n",
    "            io.imsave(savepath,np.uint8(crop_outli*(2**8-1)))\n",
    "            \n",
    "            # save the masks\n",
    "            savepath = os.path.join(basedir,'crop_masks'+ext)\n",
    "            io.imsave(savepath,np.uint8(crop_masks))\n",
    "            \n",
    "            # save the flows\n",
    "            savepath = os.path.join(basedir,'crop_flows'+ext)\n",
    "            skimage.io.imsave(savepath,np.uint8(flows[j][0][slc]))\n",
    "            \n",
    "            # save the distance\n",
    "            savepath = os.path.join(basedir,'crop_dist'+ext)\n",
    "            dist = omnipose.utils.rescale(flows[j][2][slc])\n",
    "            cmap = mpl.cm.get_cmap('plasma')\n",
    "            pic = cmap(dist)\n",
    "            pic[:,:,-1] = crop_masks>0\n",
    "            skimage.io.imsave(savepath,np.uint8(pic*(2**8-1)))\n",
    "            \n",
    "            # save the boundary\n",
    "            savepath = os.path.join(basedir,'crop_bd'+ext)\n",
    "            dist = omnipose.utils.rescale(flows[j][4][slc])\n",
    "            cmap = mpl.cm.get_cmap('viridis')\n",
    "            pic = cmap(dist)\n",
    "            pic[:,:,-1] = crop_masks>0\n",
    "            skimage.io.imsave(savepath,np.uint8(pic*(2**8-1)))\n",
    "\n",
    "            #save a grayscale version for adobe illustator vectorization \n",
    "            ncl = ncolor.label(crop_masks)\n",
    "            grey_n = np.stack([1-omnipose.utils.rescale(ncl)]*3,axis=-1)\n",
    "            savepath = os.path.join(basedir,'masks_gray'+ext)\n",
    "            io.imsave(savepath,np.uint8(grey_n*(2**8-1)))\n",
    "\n",
    "            if j==2:\n",
    "                membrane = omnipose.utils.normalize99(imgs[1][slc])\n",
    "                img0 = np.stack([membrane,crop_img,np.zeros_like(crop_img)],axis=-1)\n",
    "                savepath = os.path.join(basedir,'crop_img_rgb'+ext)\n",
    "                io.imsave(savepath,np.uint8(img0*(2**8-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flows[j][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
