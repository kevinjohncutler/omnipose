{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time, os, sys\n",
    "\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "import delta\n",
    "# delta.assets.download_assets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script runs the segmentation U-Net\n",
    "For mother machine data, it runs on images of cropped out and resized single\n",
    "chambers as fed to it in Pipeline processing.\n",
    "\n",
    "The images are processed by batches of 4096 to prevent memory issues.\n",
    "\n",
    "@author: jblugagne\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from delta.data import saveResult_seg, predictGenerator_seg, postprocess, readreshape\n",
    "from delta.model import unet_seg\n",
    "import delta.utilities as utils\n",
    "from delta.utilities import cfg\n",
    "\n",
    "# Load config:\n",
    "cfg.load_config(presets=\"2D\")\n",
    "# cfg.load_config(presets=\"mothermachine\")\n",
    "\n",
    "\n",
    "# Input image sequence (change to whatever images sequence you want to evaluate):\n",
    "inputs_folder = '/home/kcutler/DataDrive/omnipose_all/small/test'\n",
    "\n",
    "# # For mother machine instead:\n",
    "# cfg.load_config(presets='mothermachine')\n",
    "\n",
    "# # Images sequence (change to whatever images sequence you want to evaluate):\n",
    "# inputs_folder = os.path.join(cfg.eval_movie,'cropped_rois')\n",
    "\n",
    "# Outputs folder:\n",
    "outputs_folder = os.path.join(inputs_folder, \"DeLTA\")\n",
    "if not os.path.exists(outputs_folder):\n",
    "    os.makedirs(outputs_folder)\n",
    "\n",
    "# List files in inputs folder:\n",
    "unprocessed = sorted(\n",
    "    glob.glob(inputs_folder + \"/*img.tif\")\n",
    ")\n",
    "\n",
    "# Load up model:\n",
    "model = unet_seg(input_size=cfg.target_size_seg + (1,))\n",
    "model.load_weights(cfg.model_file_seg)\n",
    "\n",
    "# Process\n",
    "while unprocessed:\n",
    "    # Pop out filenames\n",
    "    ps = min(4096, len(unprocessed))  # 4096 at a time\n",
    "    to_process = unprocessed[0:ps]\n",
    "    del unprocessed[0:ps]\n",
    "\n",
    "    # Input data generator:\n",
    "    predGene = predictGenerator_seg(\n",
    "        inputs_folder,\n",
    "        files_list=to_process,\n",
    "        target_size=cfg.target_size_seg,\n",
    "        crop=cfg.crop_windows,\n",
    "    )\n",
    "\n",
    "    # mother machine: Don't crop images into windows\n",
    "    if not cfg.crop_windows:\n",
    "        # Predictions:\n",
    "        results = model.predict(predGene, verbose=1)[:, :, :, 0]\n",
    "\n",
    "    # 2D: Cut into overlapping windows\n",
    "    else:\n",
    "        img = readreshape(\n",
    "            os.path.join(inputs_folder, to_process[0]),\n",
    "            target_size=cfg.target_size_seg,\n",
    "            crop=True,\n",
    "        )\n",
    "        # Create array to store predictions\n",
    "        results = np.zeros((len(to_process), img.shape[0], img.shape[1], 1)) #bad, assumes the same shape everywhere ?\n",
    "        print(img.shape)\n",
    "        \n",
    "        \n",
    "        # Crop, segment, stitch and store predictions in results\n",
    "        for i in range(len(to_process)):\n",
    "            # Crop each frame into overlapping windows:\n",
    "            windows, loc_y, loc_x = utils.create_windows(\n",
    "                next(predGene)[0, :, :], target_size=cfg.target_size_seg\n",
    "            )\n",
    "            # We have to play around with tensor dimensions to conform to\n",
    "            # tensorflow's functions:\n",
    "            windows = windows[:, :, :, np.newaxis]\n",
    "            # Predictions:\n",
    "            pred = model.predict(windows, verbose=1, steps=windows.shape[0])\n",
    "            print(pred.shape)\n",
    "            # Stich prediction frames back together:\n",
    "            pred = utils.stitch_pic(pred[:, :, :, 0], loc_y, loc_x)\n",
    "            print(pred.shape)\n",
    "            pred = pred[np.newaxis, :, :, np.newaxis]  # Mess around with dims\n",
    "\n",
    "            results[i] = pred\n",
    "\n",
    "    # Post process results (binarize + light morphology-based cleaning):\n",
    "    results = postprocess(results, crop=cfg.crop_windows)\n",
    "\n",
    "    # Save to disk:\n",
    "    saveResult_seg(outputs_folder, results, files_list=to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from IPython import display\n",
    "\n",
    "files_folder = '/home/kcutler/DataDrive/omnipose_all/small/test'\n",
    "images = glob.glob(files_folder+'/*img.tif')\n",
    "images.sort()\n",
    "\n",
    "# Load config:\n",
    "cfg.load_config(presets='2D')\n",
    "savefile = cfg.model_file_seg\n",
    "\n",
    "# Load weights from file:\n",
    "model.load_weights(savefile)\n",
    "\n",
    "for filename in images:\n",
    "    \n",
    "    # Read image:\n",
    "    I = cv2.imread(filename, cv2.IMREAD_ANYDEPTH)\n",
    "    # Rescale to 0-1:\n",
    "    I = (I.astype(np.float32)-np.min(I))/np.ptp(I)\n",
    "    # Run prediction:\n",
    "    y = model.predict(I[np.newaxis,:,:,np.newaxis])\n",
    "    # Display output:\n",
    "    plt.imshow(y[0,:,:,0])\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from delta.utilities import cfg\n",
    "from delta.model import unet_seg\n",
    "from delta.data import trainGenerator_seg\n",
    "\n",
    "# Load config:\n",
    "cfg.load_config(presets='2D')\n",
    "\n",
    "# Files:\n",
    "# Point to extracted folder:\n",
    "training_set = 'home/kcutler/DataDrive/omnipose_all/train_sorted_website'\n",
    "\n",
    "# Overwrite seg model:\n",
    "savefile = cfg.model_file_seg\n",
    "\n",
    "# Training parameters:\n",
    "batch_size = 4\n",
    "epochs = 600\n",
    "steps_per_epoch = 300\n",
    "patience = 50\n",
    "\n",
    "#Data generator parameters:\n",
    "data_gen_args = dict(\n",
    "    rotation = 2,\n",
    "    rotations_90d = True,\n",
    "    zoom=.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    histogram_voodoo=True,\n",
    "    illumination_voodoo=True,\n",
    "    gaussian_noise = 0.03,\n",
    "    gaussian_blur = 1\n",
    "    )\n",
    "\n",
    "# Generator init:\n",
    "myGene = trainGenerator_seg(\n",
    "    batch_size,\n",
    "    os.path.join(training_set,'img'),\n",
    "    os.path.join(training_set,'seg'),\n",
    "    os.path.join(training_set,'wei'),\n",
    "    augment_params = data_gen_args,\n",
    "    target_size = cfg.target_size_seg,\n",
    "    crop_windows = cfg.crop_windows\n",
    "    )\n",
    "\n",
    "# Define model:\n",
    "model = unet_seg(input_size = cfg.target_size_seg+(1,))\n",
    "model.summary()\n",
    "\n",
    "# Callbacks:\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    savefile, monitor='loss', verbose=2, save_best_only=True\n",
    "    )\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss', mode='min', verbose=2, patience=patience\n",
    "    )\n",
    "\n",
    "# Train:\n",
    "history = model.fit(\n",
    "    myGene,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=[model_checkpoint, early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5py.File('/home/kcutler/DataDrive/DeLTA/delta/assets/models/unet_pads_track.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiSiCgui",
   "language": "python",
   "name": "misicgui"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
